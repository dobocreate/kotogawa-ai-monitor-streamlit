"""
AIå­¦ç¿’çµæœãƒšãƒ¼ã‚¸
ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ³ã¨äºˆæ¸¬ç²¾åº¦ã‚’å¯è¦–åŒ–ï¼ˆå­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­ã‚’çµ±åˆï¼‰
"""

import streamlit as st
from pathlib import Path
import pickle
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta, timezone
import numpy as np
import json
from typing import Dict, List, Optional
import subprocess
import sys

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIå­¦ç¿’çµæœ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å¤§ãã */
    [data-testid="stSidebar"] [data-testid="stSidebarNav"] a {
        font-size: 18px !important;
        font-weight: 500 !important;
        padding: 0.75rem 1rem !important;
        line-height: 1.5 !important;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆ */
    [data-testid="stSidebar"] [data-testid="stSidebarNav"] a span {
        font-size: 18px !important;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã®ã‚¢ã‚¤ã‚³ãƒ³ */
    [data-testid="stSidebar"] [data-testid="stSidebarNav"] a [data-testid="stMarkdownContainer"] p {
        font-size: 20px !important;
        margin-right: 0.5rem !important;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ“Š AIå­¦ç¿’çµæœ")
st.markdown("æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’çŠ¶æ³ã€ãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­ã€äºˆæ¸¬ç²¾åº¦ã‚’ç¢ºèªã—ã¾ã™ã€‚")


def load_dual_model_info():
    """ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    try:
        import sys
        sys.path.append(str(Path(__file__).parent.parent))
        from scripts.river_dual_model_predictor import RiverDualModelPredictor
        
        predictor = RiverDualModelPredictor()
        if predictor.load_models():
            return predictor.get_model_info()
        return None
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def load_prediction_stats():
    """äºˆæ¸¬çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    try:
        from scripts.prediction_storage import PredictionStorage
        storage = PredictionStorage()
        return storage.get_recent_predictions_count()
    except:
        return {"last_hour": 0, "last_24h": 0, "total": 0}


def load_recent_diagnostics():
    """æœ€æ–°ã®è¨ºæ–­çµæœã‚’èª­ã¿è¾¼ã¿"""
    diagnostics_dir = Path('diagnostics')
    if not diagnostics_dir.exists():
        return None
    
    # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    json_files = list(diagnostics_dir.glob('*.json'))
    if not json_files:
        return None
    
    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return None


def load_diagnostics_history(days=7):
    """æŒ‡å®šæœŸé–“ã®è¨ºæ–­å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
    diagnostics_dir = Path('diagnostics')
    if not diagnostics_dir.exists():
        return []
    
    history = []
    cutoff_date = datetime.now() - timedelta(days=days)
    
    for json_file in diagnostics_dir.glob('*.json'):
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥æ™‚ã‚’æŠ½å‡º
        try:
            file_date = datetime.fromtimestamp(json_file.stat().st_mtime)
            if file_date > cutoff_date:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    history.append({
                        'timestamp': file_date,
                        'data': data
                    })
        except:
            continue
    
    return sorted(history, key=lambda x: x['timestamp'])


def format_mae(mae_value):
    """MAEå€¤ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if mae_value is None:
        return "ãƒ‡ãƒ¼ã‚¿ãªã—"
    return f"Â±{mae_value:.3f}m"


def get_accuracy_emoji(mae_value):
    """ç²¾åº¦ã«å¿œã˜ãŸçµµæ–‡å­—ã‚’è¿”ã™"""
    if mae_value is None:
        return "âš«"
    elif mae_value < 0.05:
        return "ğŸŸ¢"  # å„ªç§€
    elif mae_value < 0.10:
        return "ğŸŸ¡"  # è‰¯å¥½
    else:
        return "ğŸ”´"  # è¦æ”¹å–„


def plot_step_accuracy(metrics_by_step):
    """ã‚¹ãƒ†ãƒƒãƒ—åˆ¥ç²¾åº¦ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    steps = []
    mae_values = []
    rmse_values = []
    
    for step_label, metrics in sorted(metrics_by_step.items(), 
                                    key=lambda x: int(x[0].replace('min', ''))):
        time_minutes = int(step_label.replace('min', ''))
        steps.append(time_minutes)
        mae_values.append(metrics.get('mae'))
        rmse_values.append(metrics.get('rmse'))
    
    fig = go.Figure()
    
    # MAEã®ãƒ©ã‚¤ãƒ³
    fig.add_trace(go.Scatter(
        x=steps,
        y=mae_values,
        mode='lines+markers',
        name='MAEï¼ˆå¹³å‡çµ¶å¯¾èª¤å·®ï¼‰',
        line=dict(color='blue', width=3),
        marker=dict(size=8)
    ))
    
    # RMSEã®ãƒ©ã‚¤ãƒ³
    fig.add_trace(go.Scatter(
        x=steps,
        y=rmse_values,
        mode='lines+markers',
        name='RMSEï¼ˆäºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®ï¼‰',
        line=dict(color='red', width=3, dash='dash'),
        marker=dict(size=8)
    ))
    
    # ç²¾åº¦åŸºæº–ç·š
    fig.add_hline(y=0.05, line_dash="dot", line_color="green", 
                  annotation_text="å„ªç§€ãƒ¬ãƒ™ãƒ«ï¼ˆÂ±5cmï¼‰")
    fig.add_hline(y=0.10, line_dash="dot", line_color="orange", 
                  annotation_text="è‰¯å¥½ãƒ¬ãƒ™ãƒ«ï¼ˆÂ±10cmï¼‰")
    
    fig.update_layout(
        title="äºˆæ¸¬æ™‚é–“åˆ¥ã®ç²¾åº¦",
        xaxis_title="äºˆæ¸¬æ™‚é–“ï¼ˆåˆ†ï¼‰",
        yaxis_title="èª¤å·®ï¼ˆmï¼‰",
        height=400,
        hovermode='x unified',
        xaxis=dict(
            tickmode='linear',
            tick0=10,
            dtick=20
        )
    )
    
    return fig


def plot_adaptive_learning_timeline(diagnostics_history):
    """é©å¿œãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤º"""
    if not diagnostics_history:
        return None
    
    fig = go.Figure()
    
    timestamps = []
    mae_values = []
    sample_counts = []
    
    for entry in diagnostics_history:
        timestamps.append(entry['timestamp'])
        data = entry['data']
        mae_values.append(data.get('final_metrics', {}).get('mae'))
        sample_counts.append(data.get('training_stats', {}).get('total_samples', 0))
    
    # MAEã®æ¨ç§»
    fig.add_trace(go.Scatter(
        x=timestamps,
        y=mae_values,
        mode='lines+markers',
        name='MAEæ¨ç§»',
        yaxis='y',
        line=dict(color='blue', width=2)
    ))
    
    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã®æ¨ç§»ï¼ˆç¬¬2è»¸ï¼‰
    fig.add_trace(go.Bar(
        x=timestamps,
        y=sample_counts,
        name='å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°',
        yaxis='y2',
        opacity=0.3,
        marker_color='lightgreen'
    ))
    
    fig.update_layout(
        title="é©å¿œãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ¨ç§»",
        xaxis_title="æ—¥æ™‚",
        yaxis=dict(
            title="MAE (m)",
            side='left'
        ),
        yaxis2=dict(
            title="å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°",
            overlaying='y',
            side='right'
        ),
        height=400,
        hovermode='x unified'
    )
    
    return fig


def show_adaptive_model_execution_steps(latest_diagnostics):
    """é©å¿œãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ãªå®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º"""
    st.subheader("ğŸ”„ é©å¿œãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—è©³ç´°")
    
    if not latest_diagnostics:
        st.info("è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # å®Ÿè¡Œæƒ…å ±
    execution_info = latest_diagnostics.get('execution_info', {})
    training_stats = latest_diagnostics.get('training_stats', {})
    
    # ã‚¿ãƒ–ã§å„ãƒ•ã‚§ãƒ¼ã‚ºã‚’è¡¨ç¤º
    tabs = st.tabs(["ğŸ“¥ ãƒ‡ãƒ¼ã‚¿åé›†", "ğŸ”§ å‰å‡¦ç†", "ğŸ“š å­¦ç¿’", "âœ… æ¤œè¨¼", "ğŸ“‹ å®Ÿè¡Œãƒ­ã‚°"])
    
    with tabs[0]:  # ãƒ‡ãƒ¼ã‚¿åé›†
        st.markdown("### ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚§ãƒ¼ã‚º")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å®Ÿè¡Œæ™‚åˆ»", execution_info.get('start_time', 'N/A'))
        with col2:
            st.metric("åé›†å…ƒ", execution_info.get('source', 'GitHub Actions'))
        with col3:
            st.metric("åé›†ãƒ‡ãƒ¼ã‚¿æ•°", training_stats.get('total_samples', 0))
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ª
        data_quality = training_stats.get('data_quality', {})
        if data_quality:
            st.markdown("#### ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
            quality_df = pd.DataFrame({
                'é …ç›®': ['æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿', 'ã‚¹ã‚­ãƒƒãƒ—', 'ã‚¨ãƒ©ãƒ¼'],
                'ä»¶æ•°': [
                    data_quality.get('valid', 0),
                    data_quality.get('skipped', 0),
                    data_quality.get('errors', 0)
                ]
            })
            st.bar_chart(quality_df.set_index('é …ç›®'))
    
    with tabs[1]:  # å‰å‡¦ç†
        st.markdown("### å‰å‡¦ç†ãƒ•ã‚§ãƒ¼ã‚º")
        
        preprocessing = training_stats.get('preprocessing', {})
        if preprocessing:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### æ¬ æå€¤å‡¦ç†")
                st.info(f"å‡¦ç†æ¸ˆã¿: {preprocessing.get('missing_handled', 0)}ä»¶")
                
            with col2:
                st.markdown("#### ç•°å¸¸å€¤æ¤œå‡º")
                st.info(f"æ¤œå‡ºæ•°: {preprocessing.get('outliers_detected', 0)}ä»¶")
        
        # ç‰¹å¾´é‡æƒ…å ±
        st.markdown("#### ä½¿ç”¨ç‰¹å¾´é‡")
        features = [
            "æ²³å·æ°´ä½ï¼ˆç¾åœ¨å€¤ï¼‰",
            "ãƒ€ãƒ æ”¾æµé‡",
            "ãƒ€ãƒ æµå…¥é‡",
            "10åˆ†é–“é™é›¨é‡",
            "1æ™‚é–“é™é›¨é‡",
            "è²¯æ°´ç‡"
        ]
        for feature in features:
            st.write(f"â€¢ {feature}")
    
    with tabs[2]:  # å­¦ç¿’
        st.markdown("### å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### å­¦ç¿’å‰")
            initial_metrics = latest_diagnostics.get('initial_metrics', {})
            st.metric("MAE", format_mae(initial_metrics.get('mae')))
            st.metric("RMSE", format_mae(initial_metrics.get('rmse')))
        
        with col2:
            st.markdown("#### å­¦ç¿’å¾Œ")
            final_metrics = latest_diagnostics.get('final_metrics', {})
            mae_improvement = None
            if initial_metrics.get('mae') and final_metrics.get('mae'):
                mae_improvement = (initial_metrics['mae'] - final_metrics['mae']) / initial_metrics['mae'] * 100
            
            st.metric("MAE", format_mae(final_metrics.get('mae')), 
                     f"{mae_improvement:.1f}%" if mae_improvement else None)
            st.metric("RMSE", format_mae(final_metrics.get('rmse')))
        
        # å­¦ç¿’è©³ç´°
        st.markdown("#### å­¦ç¿’çµ±è¨ˆ")
        stats_df = pd.DataFrame({
            'é …ç›®': ['å‡¦ç†æ™‚é–“', 'å­¦ç¿’ãƒ¬ãƒ¼ãƒˆ', 'ãƒãƒƒãƒã‚µã‚¤ã‚º'],
            'å€¤': [
                f"{training_stats.get('processing_time', 0):.2f}ç§’",
                "è‡ªå‹•èª¿æ•´",
                "1ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ï¼‰"
            ]
        })
        st.table(stats_df)
    
    with tabs[3]:  # æ¤œè¨¼
        st.markdown("### æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º")
        
        # ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
        drift_info = latest_diagnostics.get('drift_detection', {})
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º")
            drift_detected = drift_info.get('detected', False)
            if drift_detected:
                st.error("âš ï¸ ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º")
            else:
                st.success("âœ… æ­£å¸¸")
            
            st.metric("ãƒ‰ãƒªãƒ•ãƒˆç‡", f"{drift_info.get('rate', 0):.1f}%")
        
        with col2:
            st.markdown("#### ç²¾åº¦è©•ä¾¡")
            accuracy_status = "æ”¹å–„" if mae_improvement and mae_improvement > 0 else "æ‚ªåŒ–"
            st.info(f"å‰å›æ¯”: {accuracy_status}")
            
            # æ¨å¥¨äº‹é …
            st.markdown("#### æ¨å¥¨äº‹é …")
            if drift_detected:
                st.warning("ãƒ¢ãƒ‡ãƒ«ã®å†åˆæœŸåŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            elif mae_improvement and mae_improvement < -10:
                st.warning("ç²¾åº¦ãŒæ‚ªåŒ–ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            else:
                st.success("æ­£å¸¸ã«å­¦ç¿’ãŒé€²è¡Œã—ã¦ã„ã¾ã™")
    
    with tabs[4]:  # å®Ÿè¡Œãƒ­ã‚°
        st.markdown("### å®Ÿè¡Œãƒ­ã‚°")
        
        # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        logs = latest_diagnostics.get('logs', [])
        if logs:
            log_text = "\n".join([f"[{log.get('time', '')}] {log.get('level', '')}: {log.get('message', '')}" 
                                 for log in logs[-20:]])  # æœ€æ–°20ä»¶
            st.text_area("ãƒ­ã‚°å‡ºåŠ›", log_text, height=300)
        else:
            st.info("ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        
        # ã‚¨ãƒ©ãƒ¼/è­¦å‘Šã‚µãƒãƒªãƒ¼
        error_count = sum(1 for log in logs if log.get('level') == 'ERROR')
        warning_count = sum(1 for log in logs if log.get('level') == 'WARNING')
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ã‚¨ãƒ©ãƒ¼æ•°", error_count)
        with col2:
            st.metric("è­¦å‘Šæ•°", warning_count)


# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# 1. ãƒ¢ãƒ‡ãƒ«æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.header("1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«æ¦‚è¦")

model_info = load_dual_model_info()

if model_info:
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ”· åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ï¼ˆå›ºå®šï¼‰")
        base_info = model_info.get('base_model', {})
        
        if base_info.get('loaded'):
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            st.info("ğŸ“Œ åˆæœŸå­¦ç¿’æ¸ˆã¿ãƒ»æ›´æ–°ãªã—")
            
            metrics_col1, metrics_col2 = st.columns(2)
            with metrics_col1:
                st.metric("å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{base_info.get('samples', 0):,}")
            with metrics_col2:
                mae = base_info.get('mae_10min')
                emoji = get_accuracy_emoji(mae)
                st.metric(f"MAE (10åˆ†å…ˆ) {emoji}", format_mae(mae))
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
    
    with col2:
        st.subheader("ğŸ”¶ é©å¿œãƒ¢ãƒ‡ãƒ«ï¼ˆç¶™ç¶šå­¦ç¿’ï¼‰")
        adaptive_info = model_info.get('adaptive_model', {})
        
        if adaptive_info.get('loaded'):
            st.success("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            st.info("ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç¶™ç¶šå­¦ç¿’ä¸­")
            
            metrics_col1, metrics_col2 = st.columns(2)
            with metrics_col1:
                st.metric("å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{adaptive_info.get('samples', 0):,}")
                st.metric("è¿½åŠ å­¦ç¿’æ•°", f"+{adaptive_info.get('additional_samples', 0):,}")
            with metrics_col2:
                mae = adaptive_info.get('mae_10min')
                emoji = get_accuracy_emoji(mae)
                st.metric(f"MAE (10åˆ†å…ˆ) {emoji}", format_mae(mae))
        else:
            st.error("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
else:
    st.warning("ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")

# 2. å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆçµ±åˆï¼‰
st.header("2ï¸âƒ£ å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­")

# æœ€æ–°ã®è¨ºæ–­çµæœã‚’èª­ã¿è¾¼ã¿
latest_diagnostics = load_recent_diagnostics()
diagnostics_history = load_diagnostics_history(days=7)

# åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¨é©å¿œãƒ¢ãƒ‡ãƒ«ã®ã‚¿ãƒ–
model_tabs = st.tabs(["ğŸ”· åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è¨ºæ–­", "ğŸ”¶ é©å¿œãƒ¢ãƒ‡ãƒ«è¨ºæ–­"])

with model_tabs[0]:  # åŸºæœ¬ãƒ¢ãƒ‡ãƒ«
    st.info("åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã¯åˆæœŸå­¦ç¿’ã®ã¿ã§ã€ç¶™ç¶šå­¦ç¿’ã¯è¡Œã„ã¾ã›ã‚“ã€‚")
    
    if model_info and model_info.get('base_model', {}).get('loaded'):
        st.markdown("### åˆæœŸå­¦ç¿’æƒ…å ±")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "ãƒ‡ãƒ¢CSVãƒ•ã‚¡ã‚¤ãƒ«")
        with col2:
            st.metric("å­¦ç¿’æœŸé–“", "2023/6/25-7/1")
        with col3:
            st.metric("åˆæœŸMAE", format_mae(model_info['base_model'].get('mae_10min')))
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§
        st.markdown("### å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§")
        st.write("""
        - å®Ÿéš›ã®åšæ±å·ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        - 10åˆ†é–“éš”ã®ãƒ‡ãƒ¼ã‚¿
        - ç´„1é€±é–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿
        - æ™´å¤©æ™‚ã€é›¨å¤©æ™‚ã€ãƒ€ãƒ æ”¾æµæ™‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€
        """)

with model_tabs[1]:  # é©å¿œãƒ¢ãƒ‡ãƒ«
    if latest_diagnostics:
        # è©³ç´°ãªå®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’è¡¨ç¤º
        show_adaptive_model_execution_steps(latest_diagnostics)
        
        # å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•
        if diagnostics_history:
            st.markdown("### ğŸ“ˆ å­¦ç¿’å±¥æ­´")
            timeline_fig = plot_adaptive_learning_timeline(diagnostics_history)
            if timeline_fig:
                st.plotly_chart(timeline_fig, use_container_width=True)
    else:
        st.info("è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã®ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚")
        
        # æ‰‹å‹•å®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ä»Šã™ãå­¦ç¿’ã‚’å®Ÿè¡Œ", type="primary"):
            with st.spinner("å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œä¸­..."):
                try:
                    result = subprocess.run(
                        [sys.executable, "scripts/streaming_train_with_diagnostics.py"],
                        capture_output=True,
                        text=True,
                        timeout=300
                    )
                    
                    if result.returncode == 0:
                        st.success("âœ… å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        st.experimental_rerun()
                    else:
                        st.error("âŒ å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                        st.text(result.stderr)
                except subprocess.TimeoutExpired:
                    st.error("â±ï¸ å­¦ç¿’ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†ï¼‰")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")

# 3. äºˆæ¸¬ç²¾åº¦åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.header("3ï¸âƒ£ äºˆæ¸¬ç²¾åº¦åˆ†æ")

# æœ€æ–°ã®è¨ºæ–­çµæœã‹ã‚‰ç²¾åº¦æƒ…å ±ã‚’è¡¨ç¤º
if latest_diagnostics:
    # ã‚¹ãƒ†ãƒƒãƒ—åˆ¥ç²¾åº¦
    metrics_by_step = latest_diagnostics.get('metrics_by_step', {})
    if metrics_by_step:
        st.subheader("ğŸ“Š äºˆæ¸¬æ™‚é–“åˆ¥ã®ç²¾åº¦")
        step_fig = plot_step_accuracy(metrics_by_step)
        st.plotly_chart(step_fig, use_container_width=True)
        
        # ç²¾åº¦ã‚µãƒãƒªãƒ¼
        st.subheader("ğŸ“‹ ç²¾åº¦ã‚µãƒãƒªãƒ¼")
        summary_data = []
        for step_label, metrics in sorted(metrics_by_step.items(), 
                                        key=lambda x: int(x[0].replace('min', ''))):
            mae = metrics.get('mae')
            emoji = get_accuracy_emoji(mae)
            summary_data.append({
                'äºˆæ¸¬æ™‚é–“': step_label,
                'ç²¾åº¦è©•ä¾¡': emoji,
                'MAE': format_mae(mae),
                'RMSE': format_mae(metrics.get('rmse'))
            })
        
        summary_df = pd.DataFrame(summary_data)
        st.dataframe(summary_df, hide_index=True, use_container_width=True)

# äºˆæ¸¬çµ±è¨ˆ
st.header("4ï¸âƒ£ äºˆæ¸¬çµ±è¨ˆ")
pred_stats = load_prediction_stats()

col1, col2, col3 = st.columns(3)
with col1:
    st.metric("éå»1æ™‚é–“ã®äºˆæ¸¬å›æ•°", pred_stats.get('last_hour', 0))
with col2:
    st.metric("éå»24æ™‚é–“ã®äºˆæ¸¬å›æ•°", pred_stats.get('last_24h', 0))
with col3:
    st.metric("ç·äºˆæ¸¬å›æ•°", f"{pred_stats.get('total', 0):,}")

# ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
st.markdown("---")
st.caption("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: é©å¿œãƒ¢ãƒ‡ãƒ«ã¯6æ™‚é–“ã”ã¨ã«è‡ªå‹•çš„ã«å­¦ç¿’ã•ã‚Œã¾ã™ã€‚æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½ã§ã™ã€‚")